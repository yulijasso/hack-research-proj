{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115df57",
   "metadata": {},
   "source": [
    "Step 0: Setup your .env file locally\n",
    "Setup your OPENAI_API_BASE key and OPENAI_API_KEY in a file .env in this same folder.\n",
    "\n",
    "# example .env contents (copy paste this into a .env file)\n",
    "OPENAI_API_BASE=yourapibase\n",
    "OPENAI_API_KEY=yourapikey\n",
    "Install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8d146",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d6e1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install sklearn plotly chromadb openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb5223",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# You don't need to change this, just run this cell\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d201f",
   "metadata": {},
   "source": [
    "Step 1: Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702c8c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985f25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c002e2",
   "metadata": {},
   "source": [
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        dataset = []\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Extract the textbook title, page number, and information\n",
    "            # based on your specific requirements\n",
    "            textbook_title = \"Case Files Internal Medicine\"\n",
    "            page_number = page.page_number\n",
    "            information = text\n",
    "            dataset.append([textbook_title, page_number, information])\n",
    "    \n",
    "    df = pd.DataFrame(dataset, columns=[\"Textbook Title\", \"Page Number\", \"Information\"])\n",
    "    return df\n",
    "\n",
    "pdf_file = \"data/Case files Internal Medicine.pdf\"\n",
    "dataset = extract_information_from_pdf(pdf_file)\n",
    "dataset.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b2a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_information_from_pdf(pdf_files):\n",
    "    dataset = []\n",
    "    for pdf_file in pdf_files:\n",
    "        textbook_title = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                page_number = page.page_number\n",
    "                information = text\n",
    "                dataset.append([textbook_title, page_number, information])\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns=[\"Textbook Title\", \"Page Number\", \"Information\"])\n",
    "    return df\n",
    "\n",
    "pdf_files = [\"data/Case files Internal Medicine.pdf\", \"data/Harrison's Principles of Internal Medicine.pdf\"]\n",
    "dataset = extract_information_from_pdf(pdf_files)\n",
    "dataset.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc1991",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "datafile_path = \"output.csv\"\n",
    "book_df = pd.read_csv(datafile_path)\n",
    "display(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5f9b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Select the \"id\", \"title\", and \"overview\" columns\n",
    "book_df = book_df[[\"Textbook Title\", \"Page Number\", \"Information\"]].copy()\n",
    "\n",
    "# drop columns that have NaNs\n",
    "book_df_clean = book_df.dropna()\n",
    "\n",
    "# Display the new DataFrame\n",
    "display(book_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff77a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Extract the textbook title, page number, and information\n",
    "            # based on your specific requirements\n",
    "            textbook_title = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "            page_number = page.page_number\n",
    "            information = text\n",
    "\n",
    "            # Print the textbook information by page\n",
    "            print(f\"Textbook Title: {textbook_title}\")\n",
    "            print(f\"Page Number: {page_number}\")\n",
    "            print(f\"Information: {information}\")\n",
    "            print(\"\\n\")  # Add a new line between pages\n",
    "\n",
    "pdf_files = [\"data/Case files Internal Medicine.pdf\", \"data/Harrison's Principles of Internal Medicine.pdf\"]\n",
    "for pdf_file in pdf_files:\n",
    "    extract_information_from_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb43b0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install --quiet chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110a940",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "## Use this one to save to memory\n",
    "# chroma_client = chromadb.Client() \n",
    "\n",
    "## Use this one to save to disk\n",
    "chroma_client = chromadb.PersistentClient(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd05931",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# You don't need to change this, just run this cell\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import os\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "                model_name=\"text-embedding-ada-002\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155a504",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"book\", embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7827069",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "datafile_path = \"output.csv\"\n",
    "book_df = pd.read_csv(datafile_path)\n",
    "display(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9028418",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Select the \"id\", \"title\", and \"overview\" columns\n",
    "book_df = book_df[[\"Textbook Title\", \"Page Number\", \"Information\"]].copy()\n",
    "\n",
    "# drop columns that have NaNs\n",
    "book_df_clean = book_df.dropna()\n",
    "\n",
    "# Display the new DataFrame\n",
    "display(book_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f08a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Add a new column that is the concatenation of the \"title\" and \"information\" columns\n",
    "#book_df_clean['text'] = book_df_clean['Textbook Title'] + \" \" + book_df_clean['Information']\n",
    "book_df_clean.loc[:, 'text'] = book_df_clean['Textbook Title'] + \" \" + book_df_clean['Information']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(book_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d829cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Create lists of documents and metadatas using list comprehension\n",
    "documents = [row['text'] for i, row in book_df_clean.iterrows()]\n",
    "metadatas = [{\"source\": \"output.csv\", \"textbook_title\": row[\"Textbook Title\"], \"Page Number\": row[\"Page Number\"], \"Information\": row[\"Information\"]} for _, row in book_df_clean.iterrows()]\n",
    "\n",
    "# Generate unique IDs for each document\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = len(documents) // batch_size + (len(documents) % batch_size != 0)\n",
    "\n",
    "# Process the data in batches\n",
    "for i in range(num_batches):\n",
    "    print(f\"Adding batch {i+1}/{num_batches}\")\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "\n",
    "    # Add the batch to the Chroma collection (triggers OpenAI embeddings for each document under the hood)\n",
    "    collection.add(\n",
    "        documents=documents[start_index:end_index],\n",
    "        metadatas=metadatas[start_index:end_index],\n",
    "        ids=ids[start_index:end_index]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38679a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_results = 10\n",
    "results = collection.query(\n",
    "    query_texts=[\"Cardiogenic shock\"],\n",
    "    n_results=n_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91dbf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e545d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(n_results):\n",
    "    title = results[\"metadatas\"][0][i][\"textbook_title\"]\n",
    "    information = results[\"metadatas\"][0][i][\"Information\"]\n",
    "    page_number = results[\"metadatas\"][0][i][\"Page Number\"]\n",
    "   \n",
    "    \n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(title)\n",
    "    print(information)\n",
    "    print(f\"Page Number: {page_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6801b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in range(n_results):\n",
    "    page_number = results[\"metadatas\"][0][i][\"Page Number\"]\n",
    "    title = results[\"metadatas\"][0][i][\"textbook_title\"]\n",
    "    information = results[\"metadatas\"][0][i][\"Information\"]\n",
    "    results_list.append([page_number, title, information])\n",
    "    \n",
    "results_df = pd.DataFrame(results_list, columns=['page_number','title', 'information'])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9816e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def search_medical_knowledge(query):\n",
    "    metadatas = []\n",
    "    n_results = 2\n",
    "    results = collection.query(query_texts=[query], n_results=2)\n",
    "    \n",
    "    for i in range(min(n_results, len(results[\"metadatas\"][0]))):\n",
    "        metadatas.append(results[\"metadatas\"][0][i])\n",
    "        \n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2ea66",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = search_medical_knowledge(\"Cardiogenic shock\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321079f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import gradio as gr\n",
    "import openai\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def needs_tool(response):\n",
    "    return \"Tool:\" in response\n",
    "\n",
    "def extract_call(string):\n",
    "    # regex pattern\n",
    "    pattern = r'Tool: (\\w+)\\((.*?)\\)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        tool_name = match.group(1)\n",
    "        parameters = match.group(2).replace('\"', '').split(', ')\n",
    "        return tool_name, parameters\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def invoke_tool(response):\n",
    "    tool_name, parameters = extract_call(response)\n",
    "    \n",
    "    if tool_name == \"search_medical_knowledge\":\n",
    "        tool_result = search_medical_knowledge(*parameters)\n",
    "        \n",
    "    return tool_result\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to get the AI's reply using the OpenAI API\n",
    "def get_ai_reply(message, model=\"gpt-4\", system_message=None, temperature=0, message_history=[]):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the system message to the messages list\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # Add the message history to the messages list\n",
    "    if message_history is not None:\n",
    "        messages += message_history\n",
    "    \n",
    "    if message is not None:\n",
    "        # Add the user's message to the messages list\n",
    "        messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to handle the chat interaction with the AI model\n",
    "def chat(message, chatbot_messages, history_state, dropdown_value):\n",
    "    # Initialize chatbot_messages and history_state if they are not provided\n",
    "    chatbot_messages = chatbot_messages or []\n",
    "    history_state = history_state or []\n",
    "    \n",
    "    # Try to get the AI's reply using the get_ai_reply function\n",
    "    try:\n",
    "\n",
    "        if dropdown_value == \"INTERACTIVE\":\n",
    "            \n",
    "            prompt = \"\"\"\n",
    "            You are a helpful expert medical topic tutor named LEO.\n",
    "    \n",
    "            ## Tools\n",
    "    \n",
    "            You have access to the following tools:\n",
    "            - search_medical_knowledge(query): Tool to lookup medical knowledge based on their query. Use this tool when the user is looking for medical knowledge. You don't need to know all of the patient's information, the tool doesn't need it. Be careful, the tool will return the top results in the database but not all of them may be relevant. Use your judgement when answering the user's question. Example: search_medical_knowledge(\"most painful symptoms for Cardiogenic shock\")\n",
    "    \n",
    "            ## Tool Rules\n",
    "    \n",
    "            When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "    \n",
    "            ## Using Tools\n",
    "    \n",
    "            To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "    \n",
    "            Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "    \n",
    "            ## Using Tool Responses\n",
    "            \n",
    "            You are a helpful expert medical topic tutor named LEO.\n",
    "            Answer the user's question using the response from the tool BUT answer it with questions, open ended repsonses or simple answers.\n",
    "\n",
    "            Begin the conversation by asking what the user already knows about the topic.\n",
    "            Check their answer for any inconsistencies and continue an interactive conversation.\n",
    "            Provide an answer and another question the user can answer.\n",
    "      \n",
    "            \"\"\"\n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "            You are a helpful expert medical topic tutor named Jarvis.\n",
    "    \n",
    "            ## Tools\n",
    "    \n",
    "            You have access to the following tools:\n",
    "            - search_medical_knowledge(query): Tool to lookup medical knowledge based on their query. Use this tool when the user is looking for medical knowledge. You don't need to know all of the patient's information, the tool doesn't need it. Be careful, the tool will return the top results in the database but not all of them may be relevant. Use your judgement when answering the user's question. Example: search_medical_knowledge(\"most painful symptoms for Cardiogenic shock\")\n",
    "    \n",
    "            ## Tool Rules\n",
    "    \n",
    "            When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "    \n",
    "            ## Using Tools\n",
    "    \n",
    "            To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "    \n",
    "            Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "    \n",
    "            ## Using Tool Responses\n",
    "            Answer the user's question using the response from the tool. Feel free to make it conversational\n",
    "            \"\"\"\n",
    "        ai_reply = get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the history_state list\n",
    "        history_state.append({\"role\": \"user\", \"content\": message})\n",
    "        history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "\n",
    "        while(needs_tool(ai_reply)):\n",
    "            print(ai_reply)\n",
    "            tool_result = invoke_tool(ai_reply)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {tool_result}\"})\n",
    "            ai_reply = get_ai_reply(None, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "        \n",
    "        # Append the user's message and the AI's reply to the chatbot_messages list for the UI\n",
    "        chatbot_messages.append((message, ai_reply))\n",
    "\n",
    "        # Return None (empty out the user's message textbox), the updated chatbot_messages, and the updated history_state\n",
    "    except Exception as e:\n",
    "        # If an error occurs, raise a Gradio error\n",
    "        raise gr.Error(e)\n",
    "        \n",
    "    return None, chatbot_messages, history_state\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to launch the chatbot interface using Gradio\n",
    "def get_chatbot_app():\n",
    "    # Create the Gradio interface using the Blocks layout\n",
    "    with gr.Blocks() as app:\n",
    "       # Create a title above the conversation\n",
    "        title = gr.Textbox(\"TUTOR\", label=\" \", readonly=True, placeholder=\"TUTOR\", style=\"text-align:center; font-size:20px; border:none;\")\n",
    "        # Create a chatbot interface for the conversation\n",
    "        chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "        # Create a dropdown menu with options \"Option 1\" and \"Option 2\"\n",
    "        dropdown = gr.inputs.Dropdown([\"Interative\", \"Non-Interactive\"], label=\"Choose Chatbox Version\")\n",
    "        # Create a textbox for the user's message\n",
    "        message = gr.Textbox(label=\"Message\")\n",
    "        # Create a state object to store the conversation history\n",
    "        history_state = gr.State()\n",
    "        # Create a button to send the user's message\n",
    "        btn = gr.Button(value=\"Send\")\n",
    "\n",
    "\n",
    "        \n",
    "        # Connect the send button to the chat function\n",
    "        btn.click(chat, inputs=[message, chatbot, history_state, dropdown], outputs=[message, chatbot, history_state])\n",
    "        # Return the app\n",
    "        return app\n",
    "# ---------------------------------------------------------------------------------------        \n",
    "# Call the launch_chatbot function to start the chatbot interface using Gradio\n",
    "app = get_chatbot_app()\n",
    "app.queue()  # this is to be able to queue multiple requests at once\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eacdf9df",
   "metadata": {},
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import gradio as gr\n",
    "import openai\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def needs_tool(response):\n",
    "    return \"Tool:\" in response\n",
    "\n",
    "def extract_call(string):\n",
    "    # regex pattern\n",
    "    pattern = r'Tool: (\\w+)\\((.*?)\\)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        tool_name = match.group(1)\n",
    "        parameters = match.group(2).replace('\"', '').split(', ')\n",
    "        return tool_name, parameters\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def invoke_tool(response):\n",
    "    tool_name, parameters = extract_call(response)\n",
    "    \n",
    "    if tool_name == \"search_medical_knowledge\":\n",
    "        tool_result = search_medical_knowledge(*parameters)\n",
    "        \n",
    "    return tool_result\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to get the AI's reply using the OpenAI API\n",
    "def get_ai_reply(message, model=\"gpt-4\", system_message=None, temperature=0, message_history=[]):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the system message to the messages list\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # Add the message history to the messages list\n",
    "    if message_history is not None:\n",
    "        messages += message_history\n",
    "    \n",
    "    if message is not None:\n",
    "        # Add the user's message to the messages list\n",
    "        messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to handle the chat interaction with the AI model\n",
    "def chat(message, chatbot_messages, history_state):\n",
    "    # Initialize chatbot_messages and history_state if they are not provided\n",
    "    chatbot_messages = chatbot_messages or []\n",
    "    history_state = history_state or []\n",
    "    \n",
    "    # Try to get the AI's reply using the get_ai_reply function\n",
    "    try:\n",
    "        prompt = \"\"\"\n",
    "        You are a helpful expert medical topic tutor named Jarvis.\n",
    "\n",
    "        ## Tools\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - search_medical_knowledge(query): Tool to lookup medical knowledge based on their query. Use this tool when the user is looking for medical knowledge. You don't need to know all of the patient's information, the tool doesn't need it. Be careful, the tool will return the top results in the database but not all of them may be relevant. Use your judgement when answering the user's question. Example: search_medical_knowledge(\"most painful symptoms for Cardiogenic shock\")\n",
    "\n",
    "        ## Tool Rules\n",
    "\n",
    "        When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "        ## Using Tools\n",
    "\n",
    "        To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "        Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "        ## Using Tool Responses\n",
    "\n",
    "        Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "        \"\"\"\n",
    "        ai_reply = get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the history_state list\n",
    "        history_state.append({\"role\": \"user\", \"content\": message})\n",
    "        history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "\n",
    "        while(needs_tool(ai_reply)):\n",
    "            print(ai_reply)\n",
    "            tool_result = invoke_tool(ai_reply)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {tool_result}\"})\n",
    "            ai_reply = get_ai_reply(None, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "        \n",
    "        # Append the user's message and the AI's reply to the chatbot_messages list for the UI\n",
    "        chatbot_messages.append((message, ai_reply))\n",
    "\n",
    "        # Return None (empty out the user's message textbox), the updated chatbot_messages, and the updated history_state\n",
    "    except Exception as e:\n",
    "        # If an error occurs, raise a Gradio error\n",
    "        raise gr.Error(e)\n",
    "        \n",
    "    return None, chatbot_messages, history_state\n",
    "\n",
    "# Define a function to launch the chatbot interface using Gradio\n",
    "def get_chatbot_app():\n",
    "    # Create the Gradio interface using the Blocks layout\n",
    "    with gr.Blocks() as app:\n",
    "        # Create a chatbot interface for the conversation\n",
    "        chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "        # Create a textbox for the user's message\n",
    "        message = gr.Textbox(label=\"Message\")\n",
    "        # Create a state object to store the conversation history\n",
    "        history_state = gr.State()\n",
    "        # Create a button to send the user's message\n",
    "        btn = gr.Button(value=\"Send\")\n",
    "\n",
    "        # Connect the send button to the chat function\n",
    "        btn.click(chat, inputs=[message, chatbot, history_state], outputs=[message, chatbot, history_state])\n",
    "        # Return the app\n",
    "        return app\n",
    "# ---------------------------------------------------------------------------------------        \n",
    "# Call the launch_chatbot function to start the chatbot interface using Gradio\n",
    "app = get_chatbot_app()\n",
    "app.queue()  # this is to be able to queue multiple requests at once\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a72f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!git add hack-research-proj.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51626075",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b31d31",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!git commit -m \"Progress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e3083",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c583d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0 (main, Oct  5 2023, 15:44:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
